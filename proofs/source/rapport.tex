\input{./proofs/source/preambule.tex}
\addbibresource{./proofs/source/rapport.bib}
\usepackage{tkz-base}
\usepackage{algorithm}
\usepackage{algorithmic}
\setlength\parindent{0pt}

% \usepackage{graphicx,txfonts}




\title{Rapport de stage:\\
Arbitrages statistiques dans l'apprentissage automatique confidentiel.
}           
\author{{\sc Alexi Canesse}, L3 informatique fondamentale,\\École Normale Supérieure de Lyon\\
Sous la supervision d'{\sc Aurélien Garivier}, Professeur,\\ UMPA et École Normale Supérieure de Lyon}
\date{\today}          

\sloppy                  

\pgfplotsset{compat=1.16}

\begin{document}


\pagenumbering{roman}
\setmathfont{Latin Modern Math}
\setmathfont[range={\mathscr,\mathbfscr}]{XITS Math}

% \maketitle




\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
            
        \Huge
        \textbf{Arbitrages statistiques dans l'apprentissage automatique confidentiel.}
            
        \vspace{0.5cm}
        \LARGE
        Rapport de stage
            
        \vspace{1.5cm}
            
        \huge {\sc Alexi Canesse}\\\LARGE
        Sous la supervision d'{\sc Aurélien Garivier}, Professeur,\\ UMPA et École Normale Supérieure de Lyon
            
        \vfill
            
        Stage de recherche effectué dans le cadre de la \\
        L3 informatique fondamental de l'ÉNS de Lyon
            
        \vspace{0.8cm}
            
        \includegraphics[width=0.5\textwidth]{"./proofs/source/logo co UDL ENS 2016.pdf"}
            
        \Large
        Département informatique\\
        École Normale Supérieur de Lyon\\
        France\\
        \today
            
    \end{center}
\end{titlepage}





\newpage

\tableofcontents
\newpage

\pagenumbering{arabic}
\section{Introduction}
TODO

\subsection{Présentation du problème}

TODO

\subsection{Définitions}

La \textit{differential privacy} \cite{10.1007/11681878_14} quantifie la perte de confidentialité subit par un individue en étant dans une base de donné. \\

\definition{Bases de donnée voisines}

On dit que deux bases de données \(x\) et \(y\) sont voisines et on note \(||x - y||_1 \leq 1\) si elles diffèrent sur au plus une entrée \textit{ie} la distance de {\sc Hamming} qui les sépare et majorée par 1.\\

\definition{Differential privacy}

On dit qu'un mécanisme aléatoire \(\mathcal M :\mathcal X^{(\N)} \to \mathcal T\) est \textbf{\((\varepsilon, \delta)\)-\textit{differentially private}} si pour tout \(\mathcal S \subset \mathcal T \) mesurable, 
\[
    \forall x,y \in \mathcal X^{(\N)} \quad ||x - y|| \leq 1 \quad \Rightarrow \quad \mathbb P(\mathcal M(x) \in \mathcal S) \leq \exp(\varepsilon)  \mathbb P(\mathcal M(y) \in \mathcal S) + \delta
\] 
De plus, si \(\delta = 0\), on dit que \(\mathcal M\) est \textbf{\(\varepsilon\)-\textit{differentially private}}.\\


\subsection{Contribution}

TODO

\section{Méthode des histogrammes}

\subsection{AboveThreshold}

Répondre à de nombreuses requête est coûteux en confidentialité. Utiliser à algorithme naïf tel que le mécanisme de {\sc Laplace} \cite{10.1007/11681878_14} ne permet pas de répondre à de nombreuses requêtes avec une bonne précision tout en préservant un bon niveau de confidentialité (\(\varepsilon\) doit être petit). Dans certains cas nous ne sommes néanmoins pas intéressé par les réponses numériques, mais uniquement intéressé par le fait qu'une réponse dépasse ou non un seuil définit. Nous allons voir que \mintinline{cpp}{AboveThreshold} \cite{dwork2014the} permet cela tout en ne payant que pour les requêtes qui dépassent le seuil.

\label{AboveThreshold}
\begin{code}
    AboveThreshold(database, queries, threshold, epsilon){
        Assert("les requêtes sont toutes de sensibilité 1");
        result = 0;
        noisyThreshold = threshold + Lap(2/epsilon);
        for(querie in queries){
            nu = Lap(4/epsilon);
            if(querie(D) + nu > noisyThreshold)
                return result;
            else
                ++result;
        }
        return -1;
    }
\end{code}

L'algorithme venant d'être décrit renvoie l'indice de la première requête à dépasser le seuil si une telle requête existe. C'est une version adaptée de l'algorithme initialement décrit par {\sc Dwork } et {\sc Roth} dans \cite[page 57]{dwork2014the}. Icelui a du sens d'un point de vue informatique mais rend le formalisme mathématiques compliqué (les auteurs eux-même tombent dans ce travers) et nous n'utiliseront pas les légers avantages de leur version.\\
 
\theoreme{}\\
Pour tout ensemble de requêtes \(Q \in \left( \mathcal X^{(\N)} \to  \mathcal T \right)^{\N}\) de sensibilité \(1\), tout seuil \(T \in \R\), tout \(\varepsilon > 0\), \(M : x \in \mathcal X^{(\N)} \mapsto \) \mintinline{cpp}{AboveThreshold(x, Q, T, epsilon)} est \(\varepsilon\)-\textit{differentially private}.\\

\textit{\textbf{Remarque:} La démonstration est une réécriture de celle du livre de référence \cite[page57]{dwork2014the}. Une réécriture était nécessaire car cette démonstration présente de nombreux points limites en terme de rigueur mathématiques et de detail pas suffisant sur certains points non triviaux.}\\ 

\textit{Démonstration}:\\
Soit \(D, D' \in \mathcal X^{(\N)}\) tels que \(||D - D'|| \leq 1\), \(\{f_i\}_i = Q \in \left( \mathcal X^{(\N)} \to  \mathcal T \right)^{\N}\) un ensemble de requêtes de sensibilité \(1\), \(T \in \R\) un seuil, et \(\varepsilon > 0\). On pose alors \(A\) la variable aléatoire \mintinline{cpp}{AboveThreshold(D, Q, T, epsilon)} et \(A'\) la variable aléatoire \mintinline{cpp}{AboveThreshold(D', Q, T, epsilon)}.\\

Soit alors \(k \in \N\). \textit{Montrons que \(\mathbb P (A = k) \leq \exp(\varepsilon)\mathbb P(A' = k)\)}. En reprenant les notations de l'algorithme [\ref{AboveThreshold}], on fixe les éléments \((\nu_i)_{i {\color{magenta} <} k}\) (qui suivent une loi de {\sc Laplace} de paramètre \(4/\varepsilon\)).\\


On pose alors
\[
    \left\{ 
        \begin{array}[]{rl}
            g_k & = \max_{i {\color{magenta} <} k} \left\{ f_i(D) + \nu_i\right\}\\
            g_k' & = \max_{i {\color{magenta} <} k} \left\{ f_i(D') + \nu_i\right\}\\
        \end{array}
    \right.    
\]

Ces grandeurs représente la valeur plus grande comparée au seuil bruité avant l'indice \(k\) dans le cas de l'execution sur \(D\) et de l'execution sur \(D'\). Les probabilité qui suivent seront prisent sur les deux variables aléatoires non fixées \(\nu_k\) et \(\hat T\) qui est la valeur du seuil bruitée. On pose enfin, pour tout \(i \in \N\),
\[
    \left\{ 
        \begin{array}[]{rl}
            y_i & = f_i(D)\\
            y_i' & = f_i(D')\\
        \end{array}
    \right.    
\]


On note alors que, en notant \(l_2\) la densité de la loi de {\sc Laplace} de paramètre \(2/\varepsilon\) et \(l_4\) celle de paramètre \(4/\varepsilon\),
\begin{align*}
    \mathbb P(A = k) & = \mathbb P(\hat T \in ]g_k, y_k + \nu_k])\\
    & = \int_{\R} \mathbb P(\hat T \in ]g_k, y_k + \nu])l_4(\nu) \dt \nu \\
    & = \int_{\R}\int_{g_k - T}^{y_k + \nu - T} l_2(t)l_4(\nu) \dt t \dt \nu 
\end{align*}

On effectue alors un premier changement de variable affine 
\[
    \hat t = t + g_k - g_k'    
\]

On obtient donc 
\begin{align*}
    \mathbb P(A = k) & = \int_{\R}\int_{g_k- T}^{y_k + \nu - T} l_2(\hat t - g_k + g_k')l_4(\nu) \dt  t \dt \nu\\
    & = \int_{\R}\int_{g_k' - T}^{y_k + \nu - g_k + g_k' - T} l_2(\hat t )l_4(\nu) \dt  t \dt \nu\\
\end{align*}

Il est alors temps de faire un second changement de variable affine
\[
    \hat \nu = \nu + g_k - g_k' + y_k' - y_k   
\]

Ainsi,
\begin{align*}
    \mathbb P(A = k) & = \int_{\R}\int_{g_k' - T}^{y_k + \nu - g_k + g_k' - T} l_2(\hat t )l_4(\hat\nu - g_k + g_k' - y_k' + y_k) \dt \hat t \dt \nu\\
    & = \int_{\R}\int_{g_k' - T}^{y_k + \nu  - g_k +g_k'  + g_k - g_k' +y_k' - y_k - T} l_2(\hat t )l_4(\hat\nu) \dt  t \dt \nu\\
    & = \int_{\R}\int_{g_k' - T }^{y_k' + \nu - T } l_2(\hat t )l_4(\hat\nu) \dt t \dt \nu\\
\end{align*}

Par définition de \(l_2\) et \(l_4\) nous avons donc
\begin{align*}
    \mathbb P(A = k) & =  \int_{\R}\int_{g_k' - T}^{y_k' + \nu -T} \exp\left(-\dfrac{|\hat t|\varepsilon}{2}\right)\exp\left(-\dfrac{|\hat\nu|\varepsilon}{4}\right) \dt t \dt \nu\\
\end{align*}

L'inégalité triangulaire assure alors que 
\begin{align*}
    \mathbb P(A = k) & \leq  \int_{\R}\int_{g_k' - T}^{y_k' + \nu - T } \exp\left(\dfrac{|\hat t - t|\varepsilon}{2}\right)\exp\left(-\dfrac{|t|\varepsilon}{2}\right)\exp\left(\dfrac{|\hat\nu - \nu|\varepsilon}{4}\right)\exp\left(-\dfrac{|\nu|\varepsilon}{4}\right) \dt t \dt \nu\\
    & =  \int_{\R}\int_{g_k' - T}^{y_k' + \nu -T} \exp\left(\dfrac{| g_k - g_k' |\varepsilon}{2}\right)\exp\left(-\dfrac{|t|\varepsilon}{2}\right)\exp\left(\dfrac{|g_k - g_k' + y_k' - y_k |\varepsilon}{4}\right)\exp\left(-\dfrac{|\nu|\varepsilon}{4}\right) \dt  t \dt \nu\\
\end{align*}

Les requêtes étant de sensibilité \(1\), nous avons 
\[
    \left\{ 
        \begin{array}[]{rlc}
            2 & \geq |g_k - g_k'| + |y_k' - y_k | & \geq|g_k - g_k' + y_k' - y_k | \\
            1 & = | g_k - g_k' | \\
        \end{array}
    \right.    
\]

Enfin, la croissance de l'intégrale assure que 
\begin{align*}
    \mathbb P(A = k) & \leq  \int_{\R}\int_{g_k' - T}^{y_k' + \nu - T} \exp\left(\dfrac{\varepsilon}{2}\right)\exp\left(-\dfrac{|t|\varepsilon}{2}\right)\exp\left(\dfrac{\varepsilon}{2}\right)\exp\left(-\dfrac{|\nu|\varepsilon}{4}\right) \dt  t \dt \nu\\
    & = \exp\left(\dfrac{2\varepsilon}{2}\right)  \int_{\R}\int_{g_k' - T}^{y_k' + \nu -T}\exp\left(-\dfrac{|t|\varepsilon}{2}\right)\exp\left(-\dfrac{|\nu|\varepsilon}{4}\right) \dt  t \dt \nu\\
    & = \exp\left(\varepsilon\right) \int_{\R}\int_{g_k' - T}^{y_k' + \nu - T}l_2(t)l_4(\nu) \dt  t \dt \nu\\
    & = \exp\left(\varepsilon\right) \int_{\R} \mathbb P(\hat T \in ]g_k', y_k' + \nu]) l_4(\nu) \dt \nu\\
    & = \exp\left(\varepsilon\right) \mathbb P(\hat T \in ]g_k', y_k' + \nu_k]) \\
    & = \exp\left(\varepsilon\right) \mathbb P(A' = k)
\end{align*}




\subsection{La méthode des histogramme}

\subsubsection{Présentation de la méthode des histogrammes}
La méthode des histogramme est une méthode que nous avons proposé durant ce stage. Il s'agit d'une instanciation particulière de \mintinline{cpp}{AboveThreshold} permettant de calculer l'ensemble des déciles (ou n'importe quel quantiles). Une transformation affine permet d'obtenir la réponse finale à partir de la réponse du mécanisme.

\begin{code}
    HistogramMethod(database, epsilon, steps, a, b){
        /* composition theorem */
        epsilon /= 9;

        result = {};
        for(d in {1 ... 9}){ /* which decile */
            T = d*card(database)/10;
            for(i in {1 ... steps}){
                fi = x -> card({element in x | element < i*(b-a)/steps});
                queries.push_back(fi);
            }
            T = d*card(database)/10;
            result.push_back(AboveThreshold(database, queries, T, epsilon)
                                *(b-a)/steps});
        }
        return result;
    }
\end{code}


Les entrée \(a\) et \(b\) donnent une minoration et une majoration de l'ensemble des valeurs d'entrées. L'algorithme découpe alors l'intervalle \([a,b]\) en \mintinline{cpp}{steps} intervalles de même tailles. Pour chaque décile, l'entier renvoyé par \mintinline{cpp}{Abovethreshold} est l'indice de la première valeur à dépasser ce décile.  

\definecolor{mycolor}{RGB}{109,7,26}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
    \draw[mycolor,->] (-7,0) -- (7,0);
    % \draw[white] (-1.425,0) -- (-1.325,0);
    \filldraw[mycolor] (-6,0) circle (2pt) node[below]{$0$};
    \filldraw[mycolor] (-3,0) circle (2pt) node[below]{\(1/4\)};
    \filldraw[mycolor] (0,0) circle (2pt) node[below]{\(1/2\)};
    % \draw[mycolor] (-1.5,-0.3) -- (-1.35, 0.3);
    % \draw[mycolor] (-1.4,-0.3) -- (-1.25, 0.3);
    \filldraw[mycolor] (3,0) circle (2pt) node[below]{3/4};
    \filldraw[mycolor] (6,0) circle (2pt) node[below]{1};
    % \filldraw[red] (2,0) circle (2pt) node[above]{$n$};
    \end{tikzpicture}
    \caption{Le découpage pour \(a = 0\), \(b = 1\), \mintinline{cpp}{steps} = 4}
\end{figure}

\theoreme{}\\
\mintinline{cpp}{HistogramMethod} est \(\varepsilon\)-\textit{differentially private}.\\


\textit{Démonstration:} Les requêtes envoyé par l'algorithme à \mintinline{cpp}{AboveThreshold} sont bien de sensibilité 1. Chacun des neuf appels à cette fonction est donc \(\varepsilon/9\)-\textit{differentially private}. Le théorème de composition assure alors que \mintinline{cpp}{HistogramMethod} est \(\varepsilon\)-\textit{differentially private}.\\

Maintenant que nous avons vu que cet algorithme est bien \textit{differentially private}, nous allons essayer d'évaluer sa précision. Cela ne sera pas évident car la précision de l'algorithme dépend beaucoup du jeu de donné en entré.\\




\lemme{\mintinline{cpp}{AboveThreshold} est \((\alpha, \beta)-accurate\)}\\
Pour tout \(\beta \in ]0,1[\), tout \(x \in \mathcal X^{(\N)}\), tout \(\{f_i\}_i = Q \in \left( \mathcal X^{(\N)} \to  \mathcal T \right)^{\N}\), tout \(\varepsilon > 0\), tout \(T \in \R\),  en posant \(\alpha = 8\left( \log(k) + \log(2/\beta) \right)/\varepsilon\) et \(k = \) \mintinline{cpp}{AboveThreshold(x, Q, T, epsilon)}, on a, en reprenant les notations de l'algorithme,
\[
    \mathbb P \left( \forall i < k \  f_i(x) + \nu_i < T + \alpha \wedge f_k(x) + \nu_k > T - \alpha \right) \geq 1 - \beta
\]

\textit{\textbf{Remarque:} Ce lemme est due à \cite[page 61]{dwork2014the}. Nous reprenons aussi la démonstration ici car la démonstration originale ne nous semble pas assez claire et trop bancale mathématiquement.}\\

\textit{Démonstration:} Reprenons les notations de l'énoncé. Montrons déjà qu'il suffit de démontrer que 
\begin{align}
    \label{accu_lemme}
    \mathbb P\left( \max_{i \leq k} |\nu_i| + |T - \hat T| < \alpha  \right)  \geq 1 - \beta   
\end{align}
où \(\hat T\) est le seuil bruité défini à la ligne 4 de l'algorithme [\ref{AboveThreshold}]. Or, nous avons, en posant pour tout \(i \leq k\), \(y_i = f_i(x)\)
\[
    y_k + \nu_k \geq \hat T \overset{\text{IT}}{\geq} T - |T-\hat T|
\]

\textit{Mutatis mutandis} 
\[
    \forall i < k \quad y_i \leq \hat T + |\nu_i| \leq T + |T - \hat T| + |\nu_i|  
\]

Ainsi,
\[
    \mathbb P \left( \forall i < k \  f_i(x) + \nu_i < T + \alpha \wedge f_k(x) + \nu_k > T - \alpha \right) \geq 1 - \beta
\]

\textit{Démontrons enfin (\ref{accu_lemme})}! La variable aléatoire \(T-\hat T\) suit une loi de {\sc Laplace} de paramètre \(2/\varepsilon\). Ainsi,
\[
    \mathbb P \left( |T - \hat T| \geq \dfrac{\alpha}{2} = \dfrac{\alpha \varepsilon}{4}\dfrac{2}{\varepsilon} \right) = \exp\left( -\dfrac{\varepsilon \alpha}{4} \right) = \exp\left( -2\left( \log k + \log \dfrac{2}{\beta} \right) \right) \leq \exp\left( -2\left(\log \dfrac{2}{\beta} \right) \right) \leq \dfrac{\beta}{2}
\]

De même,
\[
    \mathbb P \left( \max_{i} |\nu_i| \geq \dfrac{\alpha}{2} \right) \leq \sum\limits_{j = 1}^k \mathbb P \left( |\nu_j| \geq \dfrac{\alpha}{2} \right) = k \exp\left( -\dfrac{-\alpha\varepsilon}{8} \right) = k \exp\left( -\log k - \log\dfrac{2}{\beta} \right) = \dfrac{k}{k} \dfrac{\beta}{2}
\]

Enfin, 
\begin{align*}
    \mathbb P\left( \max_{i \leq k} |\nu_i| + |T - \hat T| < \alpha  \right) & \geq \mathbb P\left( \max_{i \leq k} |\nu_i| < \dfrac{\alpha}{2} \ \wedge \ |T - \hat T| < \dfrac{\alpha}{2} \right)\\
    & = 1 - \mathbb P\left( \max_{i \leq k} |\nu_i| \geq \dfrac{\alpha}{2} \ \cup \ |T - \hat T| \geq \dfrac{\alpha}{2} \right)\\
    & \geq 1 - \mathbb P\left( \max_{i \leq k} |\nu_i| \geq \dfrac{\alpha}{2}\right) - \mathbb P \left(|T - \hat T| \geq \dfrac{\alpha}{2} \right)\\
    &\geq 1 - \dfrac{\beta}{2} - \dfrac{\beta}{2}
\end{align*}

Finalement, 
\[
    \mathbb P\left( \max_{i \leq k} |\nu_i| + |T - \hat T| < \alpha  \right)  \geq 1 - \beta
\]

Ce qui démontre bien (\ref{accu_lemme}) et donc le lemme.\\

\subsubsection{Analyse de complexité}

La complexité de \mintinline{cpp}{AboveThreshold} est de l'ordre de la somme des complexité des requêtes sur le jeu de données d'entré. En notant \(n\) la taille de la base de donnée, les requêtes envoyé à \mintinline{cpp}{AboveThreshold} par \mintinline{cpp}{HistogramMethod} sont toute de complexité linéaire en \(n\). La variable \mintinline{cpp}{step} a aussi pour valeur le nombre de requêtes envoyées que l'on nommera \(k\). L'algorithme a alors une complexité en \(\O(nk)\).

\subsubsection{Analyse de précision - le cas de la distribution uniforme}

Nous allons évaluer la précision de l'algorithme à l'aide de l'erreur quadratique moyenne entre la valeur renvoyé par le programme et la valeur attendue. Il y a plusieurs manière de penser ce qu'est la valeur attendue: elle pourrait être la valeur des déciles de l'échantillons d'entré. Néanmoins, elle peut tout aussi bien être l'ensemble des déciles de la loi. En effet, nous cherchons à répondre à des questions de statistique, l'entré peut-être un simple échantillon ``représentatif'';  au quel cas nous sommes principalement intéressé par les réponses statistiques sur l'ensemble de la population et non juste sur notre échantillon.\\

Ces deux choix ont un réel sens. Nous avons d'abord essayé d'évaluer les performances de l'algorithme dans le premier cas. Les calculs était difficiles et menaient à des résultats difficilement exploitables. Nous avons donc choisi de réaliser les calculs sur la seconde option afin de pouvoir mener des calculs légèrement plus simples et ainsi avoir des résultats.\\

Nous allons commencer par démontrer quelques lemmes intermédiaires afin de démontrer les résultats de précision.\\

\lemme{Estimation de l'écard entre les déciles empiriques et ceux de la loi uniforme.}\\
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1] et soit \(\gamma \in [0,0.1]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) les déciles de la loi. Pour tout \(i \in \inte 1 9\)
\[
    \mathbb P(d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]) \geq 1 - 2\exp\left( -\dfrac{1}{12}n\gamma^2 \right)\\
\]




\textit{Démonstration:} Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1]. Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) ceux de la loi. Soit \(\gamma \in [0,0.1]\). On note que
\begin{align*}
    \mathbb P(d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]) & = 1 - \mathbb P(d_i \notin [d_i^l - \gamma/2, d_i^l + \gamma/2])\\
    & = 1 - \mathbb P(d_i \leq d_i^l - \gamma/2 \vee d_i \geq d_i^l + \gamma/2])
\end{align*}

On pose alors \(A = \) ``il y a au moins \(in/10\) valeurs plus petites que \(d_i^l - \gamma/2\)'' et \(B = \) ``il y a au plus \(in/10\) valeurs plus petites que \(d_i^l + \gamma/2\)''. On pose donc pour tout \(j\), \(A_j = \un_{x_j < d_i^l - \gamma/2}\) et \(B_j = \un_{x_j < d_i^l + \gamma/2}\).  On pose alors \(A_s = \sum_{j = 0}^{n-1} A_j\) et \(B_s = \sum_{j = 0}^{n-1} B_j\)

\begin{align*}
    \mathbb P(d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]) & = 1 - \mathbb P(A \cup B)\\
    & \geq 1 - \mathbb P(A) - \mathbb P(B)\\
    & \geq 1 - \mathbb P(A_s \geq in/10) - \mathbb P(B_s \leq in/10)\\
\end{align*}

Les événements \((A_j)_j\) suivent une loi de {\sc Bernouilli} de paramètre \(d_i^l - \gamma/2\) et les événements \((B_j)_j\) suivent une loi de {\sc Bernouilli} de paramètre \(d_i^l + \gamma/2\). Ainsi, 
\[
    \begin{array}{rcl}
        \mathbb P \left( A_s \geq in/10 \right) & \overset{d_i^l = i/10}{=} & \mathbb P \left( A_s \geq \left( d_i^l - \dfrac{\gamma}{2} \right)n\left(1 +\left(\dfrac{d_i^l}{d_i^l - \gamma/2} - 1 \right)\right)\right)\\
        & \leq & \exp\left( -\dfrac{1}{3}n\left( d_i^l - \dfrac{\gamma}{2} \right) \left(\dfrac{\gamma/2}{d_i^l - \gamma/2} \right)^2 \right)\\
        & = & \exp\left( -\dfrac{1}{12}n\gamma^2 \dfrac{1}{d_i^l - {\gamma}/{2}} \right)\\
        & \overset{d_i^l - \gamma/2 \leq 1}{\leq} & \exp\left( -\dfrac{1}{12}n\gamma^2 \right)\\
    \end{array}
\]

De même
\[
    \mathbb P\left( B_s \leq \dfrac{in}{10} \right) \leq \exp\left( -\dfrac{1}{12}n\gamma^2 \right)
\]

Finalement,
\[
    \mathbb P(d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]) \geq 1 - 2\exp\left( -\dfrac{1}{12}n\gamma^2 \right)\\
\]


\lemme{}

Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1] dont on note \((d_i^l)_i\) les déciles. Soit \(\gamma \in [0,0.1]\), \(i \in \inte 1 9 \) et \(\alpha \in \N\). Il y a au moins \(\alpha\) valeurs de \(X\) dans chacun des intervalles \([d_i^l - \gamma, d_i^l-\gamma/2]\) et \([d_i^l + \gamma/2, d_i^l+\gamma]\) avec une probabilité au moins \(1 - \beta\) avec 
\[
    \beta = 2\exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right)
\]

\textit{Démonstration:} Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1] dont on note \((d_i^l)_i\) les déciles. Soit \(\gamma \in [0,0.1]\), \(i \in \inte 1 9 \) et \(\alpha \in \N\). On pose alors pour tout \(j\), \(A_j = \un_{x_j \in d_i^l - \gamma, d_i^l - \gamma/2}\) et \(B_j = \un_{x_j \in d_i^l + \gamma/2, d_i^l + \gamma}\). On peut alors noter \(A = \sum_{j = 0}^{n-1} A_j\) et  \(B = \sum_{j = 0}^{n-1} B_j\). 
\begin{align*}
    \mathbb P \left( A \geq \alpha \ \wedge \ B \geq \alpha \right) & \geq \mathbb P (A \geq \alpha) + \mathbb P (B \geq \alpha) - 1
\end{align*}

Or, on a, à l'aide d'une nouvelle utilisation d'une borne de {\sc Chernoff},
\[
    \left\{
    \begin{array}{rcl}
        \mathbb P (A \geq \alpha) & = & 1 - \mathbb P \left(A < \dfrac{n\gamma}{2}\left(1 -\left(1 - \dfrac{2\alpha}{n\gamma}\right)\right)\right) \geq 1 - \exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right)\\
        \mathbb P (B \geq \alpha) & = & 1 - \mathbb P \left(B < \dfrac{n\gamma}{2}\left(1 -\left(1 - \dfrac{2\alpha}{n\gamma}\right)\right)\right) \geq 1 - \exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right)\\
    \end{array}
    \right.
\]

Ainsi,
\begin{align*}
    \mathbb P \left( A \geq \alpha \ \wedge \ B \geq \alpha \right) & \geq 1 - 2\exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right)
\end{align*}


La combinaison des trois lemmes précédents permet d'obtenir un résultat de précision utile sur \mintinline{cpp}{HistogramMethod}.\\


\theoreme{\((\alpha, \beta)\)-précision de \mintinline{cpp}{HistogramMethod} dans le cas uniforme sur \([0,1]\)}

Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1]. Soit \(\gamma \in [0,0.1]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i)_i\) ceux de la loi. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}.

\[
    \mathbb P\left( A_i \in [d_i^l-\gamma, d_i^l + \gamma] \right) \geq 1 - \beta - 2\exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right) -2\exp\left( -\dfrac{1}{12}n\gamma^2 \right)  
\]
Avec 
\[
    \alpha = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon} 
\]

\textit{Démonstration:} Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1]. Soit \(\gamma \in [0,0.1]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) ceux de la loi. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}.\\

On pose 
\[
    \alpha = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon}    
\]

Notons alors \(E_\alpha\) l'événement ``Il y a au moins \(\alpha\) valeurs de \(X\) dans chacun des intervalles \([d_i^l - \gamma, d_i^l-\gamma/2]\) et \([d_i^l + \gamma/2, d_i^l+\gamma]\)'' Et \(E_{A_i}\) l'événement ``moins de \(\alpha\) valeurs de \(X\) séparent \(d_i\) et \(A_i\)''. Nous avons alors 
\begin{align*}
    \mathbb P\left( A_i \in [d_i^l-\gamma, d_i^l + \gamma] \right) & \geq \mathbb P \left( E_{A_i} \wedge E_\alpha \wedge d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]  \right)\\
    & \geq \mathbb P \left( E_{A_i}\right) + \mathbb P \left( E_\alpha\right) + \mathbb P \left( d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]  \right) - 2\\
\end{align*}

Les trois précédents lemmes assurent que 
\begin{align*}
    \mathbb P\left( A_i \in [d_i^l-\gamma, d_i^l + \gamma] \right) & \geq (1 - \beta) + (1 - \mu) + (1 - \eta) - 2\\
    & \geq 1 - \beta - \mu - \eta
\end{align*}

Avec 
\[
    \alpha = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon}  \quad \wedge \quad \mu = 2\exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right) \quad \wedge \quad \eta  = 2\exp\left( -\dfrac{1}{12}n\gamma^2 \right)
\]


Ce résultat n'est pas optimal. Nous avons fait de nombreuses approximations. Néanmoins, nous avons une borne dont la croissance est exponentielle en la taille du jeu de donnée! De plus, la forme de cette borne lui permet d'être facilement exploitée. Nous allons maintenant utiliser ce théorème pour obtenir un résultat tr§s important: une majoration de l’espérance de la distance entre la valeur renvoyée par le mécanisme et un décile de la loi. Ce résultat permet de savoir quelle est l'erreur à laquelle s'attendre en pratique. \\

\theoreme{Précision moyenne de \mintinline{cpp}{HistogramMethod}}
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1]. Soit \(\gamma \in [0,0.1]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les décile de la loi. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}.
\[
    \mathbb E\left( |A_i - d_i^l| \right) \leq d_i^l\beta  + 2\sqrt \dfrac{3\pi}{n} +  \dfrac{8e^\alpha}{n} = d_i^l\beta + \O\left( \dfrac{1}{\sqrt n} \right)
\]

\textit{Démonstration:}
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1]. Soit \(\gamma \in [0,0.1]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les décile de la loi. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}. On pose enfin
\[
    F : \left\{
        \begin{array}[]{ccc}
            \R_+ & \to & [0,1]\\
            t & \mapsto & \mathbb P(|A_i - d_i^l| \leq t)
        \end{array}
    \right.   
\]

Le théorème précédent assure que 
\[
    \forall t \in [0, d_i^l] \quad F(t) := \mathbb P(|A_i - d_i^l| \leq t) \geq 1 - \beta - \mu - \eta 
\]
Avec 
\[
    \alpha = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon}  \quad \wedge \quad \mu = 2\exp\left( - \dfrac{n\gamma}{4}\left(1 - \dfrac{2\alpha}{n\gamma}\right)^2\right) \quad \wedge \quad \eta  = 2\exp\left( -\dfrac{1}{12}n\gamma^2 \right)
\]

Or, 
\[
        \mathbb E\left( |A_i - d_i^l| \right) = \int_0^{\infty} (1 - F(t))\dt t = \int_0^{d_i^l} (1 - F(t))\dt t + \int_{d_i^l}^{\infty} (1 - F(t))\dt t = \int_0^{d_i^l} (1 - F(t))\dt t + 0
\]


Ainsi,
\[
    \mathbb E\left( |A_i - d_i^l| \right) \leq \int_0^{d_i^l} (\beta + \mu + \eta)\dt t = d_i^l\beta  + \int_0^{d_i^l}\mu\dt t + \int_0^{d_i^l}\eta \dt t
\]

Notons que,
\begin{align*}
    \int_0^{d_i^l}\eta \dt t & = \int_0^{d_i^l} 2\exp\left( -\dfrac{1}{12}nt^2 \right)\dt t = \dfrac{4\sqrt 3}{\sqrt{n}}\int_0^{d_i^l} \exp\left( -t^2 \right)\dt t \leq 2\sqrt \dfrac{3\pi}{n}
\end{align*}

Mais aussi que 
\[
    \int_0^{d_i^l}\mu \dt t = 2\int_0^{d_i^l}   \exp\left( \dfrac{-nt}{4} + \alpha - \dfrac{\alpha^2}{nt} \right)\dt t \leq 2\int_0^{d_i^l}   \exp\left( \alpha - \dfrac{nt}{4} \right)\dt t = 2\dfrac{4}{n}\left[ \exp\left( \alpha - \dfrac{nt}{4} \right) \right]_0^{d_i^l}
\]

Ainsi,
\[
    \int_0^{d_i^l}\mu \dt t \leq \dfrac{8}{n}\left( e^\alpha - \exp\left( \alpha - \dfrac{nd_i^l}{4} \right) \right)  \leq \dfrac{8e^\alpha}{n}
\]

Finalement, nous avons démontré que 
\[
    \mathbb E\left( |A_i - d_i^l| \right) \leq d_i^l\beta  + 2\sqrt \dfrac{3\pi}{n} +  \dfrac{8e^\alpha}{n} = d_i^l\beta + \O\left( \dfrac{1}{\sqrt n} \right)
\]

\subsubsection{Analyse de précision - le cas de la loi normale centrée réduite}

Les lois normales est très utilisées en statistique notamment car elle permettent de modéliser les phénomènes issues de plusieurs événement aléatoires. Le théorème central limite viens jouer un rôle clé dans la prépondérance de l'utilisation de ces lois. Il semble alors crucial d'étudier la précision de notre algorithme dans le cas où les données d'entré suivent une loi normale.\\

Le théorème de précision est très analogue à celui obtenue dans le cas uniforme. Nous ne détaillons pas ici les lemmes intermédiaires et la démonstration car il s'agit formellement de la même chose. Il est néanmoins nécessaire d'introduire quelques objets usuels en plus car la loi normale est plus complexe que la loi uniforme.\\

\definition{Fonction d'erreur}

On appel fonction d'erreur la fonction suivant:
\[
        \erf: \left\{ 
        \begin{array}[]{rcl}
            \C &\to& \C\\
            z &\mapsto& \dfrac{2}{\sqrt \pi} \displaystyle\int_0^z\exp\left( -t^2 \right)\dt t
        \end{array}
        \right.
\]

\lemme{Déciles de \(\mathcal N(0,1)\).}\label{val_deciles_n01}\\
Les déciles de \(\mathcal N(0,1)\), notés \((d^l_i)_i\) sont 
\[
    \forall i \in \inte 1 9 \quad d^l_i = \sqrt{2} \erf^{-1}(2\times 0.1i - 1)
\]

\textit{Démonstration:} Soit \(i \in \inte 1 9 \). On note que 
\begin{align*}
    \dfrac{1}{\sqrt{2\pi}}\int_{-\infty}^{d^l_i} \exp\left( \dfrac{-t^2}{2}\right)\dt t &  = \dfrac{\sqrt{2}}{\sqrt{2\pi}}\int_{-\infty}^{\erf^{-1}(2\times 0.1i - 1)} \exp\left( -t^2\right)\dt t \\
    & =\dfrac{1}{2} \dfrac{2}{\sqrt{\pi}}\int_{-\infty}^{\erf^{-1}(2\times 0.1i - 1)} \exp\left( -t^2\right)\dt t \\
    & =\dfrac{1}{2} \erf\left({\erf^{-1}(2\times 0.1i - 1)}\right) + \dfrac{1}{2} \dfrac{2}{\sqrt{\pi}}\int_{-\infty}^0 \exp\left( -t^2 \right)\dt t\\
    & = 0.1i - \dfrac{1}{2} + \dfrac{1}{2}\\
    & = 0.1i
\end{align*}
La démonstration dans le cas d'une loi normale est analogue à celle du cas uniforme. Nous aurons donc des lemmes similaires. Les démonstrations seront néanmoins laissées en appendix [\ref{hmncr}].\\


\lemme{Estimation de l'écard entre les déciles empiriques et ceux de la loi normale centrée réduite.}\\
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi normale centrée réduite et soit \(\gamma \in [0, d_i^l]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) les déciles de la loi normale centrée réduite. Pour tout \(i \in \inte 1 9\)
\[
    \mathbb P(d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]) \geq 1 - \eta
\]
Avec 
\begin{align*}
    \eta & = \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - (d_i^l)^2\right)\right) + \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -(d_i^l)^2\right)  \right)
\end{align*}

\lemme{}\label{ecard_deciles_empirique_loi_n02}\\
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la normale centrée réduite. Soit \(\gamma \in [0,d^l_i]\), \(i \in \inte 1 9 \) et \(k \in \N\). Il y a au moins \(\alpha\) valeurs de \(X\) dans chacun des intervalles \([d^l_i - \gamma, d^l_i-\gamma/2]\) et \([d^l_i + \gamma/2, d^l_i+\gamma]\) avec une probabilité au moins \(1 - \beta\) avec 
\begin{align*}
    \beta & = 2\exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)
\end{align*}

\theoreme{\((\alpha, \beta)\)-précision de \mintinline{cpp}{HistogramMethod} dans le cas de la loi normale centrée réduite}\label{ecard_deciles_empirique_loi_n03}\\
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi normale centrée réduite. Soit \(\gamma \in [0,d_i^l]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) les déciles de la loi normale centrée réduite. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}.

\[
    \mathbb P\left( A_i \in [d_i^l-\gamma, d_i^l + \gamma] \right) \geq 1 - \beta - \eta -\mu    
\]
Avec 
\[
    \left\{ 
        \begin{array}{rl}
            \alpha & = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon} \\
            \mu & = 2\exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)\\
            \eta & = \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - (d_i^l)^2\right)\right) + \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -(d_i^l)^2\right)  \right)\\
        \end{array}
    \right.    
\]



\section{Le mécanisme de sensibilité inverse}

\subsection{Présentation du mécanisme}

Le mécanisme de sensibilité inverse est introduit par {\sc Hilal Asi} and {\sc John C. Duchi} dans \textit{Near Instance-Optimality in Differential Privacy} \cite{Asi2020NearII}. Le mécanisme considère l'inverse du nombre de valeurs à modifié dans un ensemble de donnée pour passer à un autre ensemble de donné sur lequel la requête a une autre valeur recherchée. Cela définit alors l'utilité d'une valeur pour instancier le mécanisme exponentiel \cite{mcsherry2007mechanism}.\\

\definition{Longueur}

Soit \(x \in \mathcal X^{(\N)}\), \(f : \mathcal X^{(\N)} \to \mathcal T\) et \(t \in \mathcal T\). La longueur est le nombre minimum de valeurs à modifier dans \(x\) pour obtenir \(x'\) tel que \(f(x') = t\). 
\[
    \len_f(x,t) = \inf_{x' \in \mathcal X^{(\N)}}\left\{|| x - x'||_1 \ |\ f(x') = t \right\}    
\]

\definition{Mécanisme de sensibilité inverse}

Soit \(f : \mathcal X^{(\N)} \to \mathcal T\) et \(\varepsilon \in \R_+\). Pour une mesure \(\mu\) sur \(\mathcal T\), on définit le mécanisme aléatoire \(M(x)\) par sa fonction de densité 
\[
    t \mapsto \dfrac{\exp(-\len_f(x, t)\varepsilon/2)}{\int_\mathcal T \exp(-\len_f(x, s)\varepsilon/2)\dt \mu(s)}    
\] 

Il n'y a qu'en \(f(x)\) que \(\len_f(x,•)\) est nulle. Ainsi le dénominateur pourrait être petit est donné une grande probabilité à des valeurs distantes de \(f(x)\). On \cite{mcsherry2007mechanism} introduit alors une version lisse du mécanisme.\\

\definition{Longueur lisse}

Soit \(x \in \mathcal X^{(\N)}\), \(f : \mathcal X^{(\N)} \to \mathcal T\) et \(\rho \in \R_+\). Si \(\mathcal N\) est une norme sur \(\mathcal T\),
\[
    \len_f^{\rho} : 
    \left\{
        \begin{array}[]{rcl}
            \mathcal T & \to & \N\\
            t & \mapsto & \inf_{s \in \mathcal T, \mathcal N(s,t) \leq \rho}\left\{\len_f(x,s) \right\}  
        \end{array}
    \right.    
\]

\definition{Mécanisme de sensibilité inverse \(\rho\)-lisse}

Soit \(f : \mathcal X^{(\N)} \to \mathcal T\) et \(\rho, \varepsilon \in \R_+\). Pour une mesure \(\mu\) sur \(\mathcal T\), on définit le mécanisme aléatoire \(M_{\text{cont}}(x)\) par sa fonction de densité 
\[
    t \mapsto \dfrac{\exp(-\len_f^\rho(x, t)\varepsilon/2)}{\int_\mathcal T \exp(-\len_f^\rho(x, s)\varepsilon/2)\dt \mu(s)}    
\] 

\theoreme{}\\
Pour tout \(\rho,\varepsilon \in \R_+\), le mécanisme de sensibilité inverse \(\rho\)-lisse est \(\varepsilon\)-\textit{differentially private}. \\

\textit{Démonstration: } Soit \(f : \mathcal X^{(\N)} \to \mathcal T\), \(\rho, \varepsilon \in \R_+\), \(\mu\) une mesure sur \(\mathcal T\), \(\mathcal S \subset \mathcal T\) mesurable et \(x,x' \in \mathcal X^{(\N)}\) voisines. \\

On note que 
\begin{align*}
    \mathbb P\left( M_{\text{cont}}(x) \in \mathcal S \right) & = \int_\mathcal S \dfrac{\exp(-\len_f^\rho(x, t)\varepsilon/2)}{\int_\mathcal T \exp(-\len_f^\rho(x, s)\varepsilon/2)\dt \mu(s)}    \dt \mu(t)\\
    & \leq \int_\mathcal S \dfrac{\exp(-(\len_f^\rho(x', t)-1)\varepsilon/2)}{\int_\mathcal T \exp(-(\len_f^\rho(x', s)+1)\varepsilon/2)\dt \mu(s)}    \dt \mu(t)\\
    & = \dfrac{\exp(\varepsilon/2)}{\exp(-\varepsilon/2)}\int_\mathcal S \dfrac{\exp(-\len_f^\rho(x', t)\varepsilon/2)}{\int_\mathcal T \exp(-\len_f^\rho(x, s)\varepsilon/2)\dt \mu(s)}    \dt \mu(t)\\
    & = \exp(\varepsilon) \mathbb P\left( M_{\text{cont}}(x') \in \mathcal S \right)
\end{align*}


\subsection{Quasi-optimalité du mécanisme de sensibilité inverse}

% \definition{Fonctions échantillon-monotone.}

% Soit \(f : \mathcal X^{(\N)} \to \R\). On dit que \(f\) est \textbf{échantillon-monotone} si pour tout \(x \in \mathcal X^n\) et \(s,t \in \R\) tels que \(f(x) \leq s \leq t\) ou \(t \leq s \leq f(x)\), 
% \[
%     \len_f(x,s) \leq \len_f(x,t)
% \]

L'article présentant le mécanisme de sensibilité inverse \cite{Asi2020NearII} détail une borne de précision sur la médiane. Nous allons ici étendre cette démonstration au cas des déciles. Dans cette section nous nous plaçons dans le cas où les données sont identiquement distribuées à partir d'une loi ayant une distribution continue \(\pi_P\) au voisinage de ses déciles \((d_i^l)_i\). Commençons par énoncé le résultat.\\

\theoreme{}\\
Soit \(\gamma \in \R_+^\star\), \(u \in [0, \gamma/4]\), \(\rho \in \R_+\) et \(X \in [0,R]^n\) dont les éléments sont obtenues à partir d'une loi \(P\) de densité \(\pi_P\) continue au voisinage de ses déciles. On pose \(p_{\text{min}, i} = \inf_{t \in [d_i^l - 2\gamma, d_i^l + 2\gamma]} \pi_P(t)\). On note \((d_i)_i\) les déciles empirique de \(X\) et \((d_i^l)_i\) les déciles de la loi. Notons alors enfin \(M_{\text{cont}}\) le mécanisme de sensibilité inverse \(\rho\)-lisse.
\[
    \mathbb P\left( |M_{\text{cont}, i} - d_i| > 2u + \rho\right) \leq \dfrac{R}{2\rho}\exp\left(- \dfrac{np_{\text{min}, i}u\varepsilon}{4} \right) + 4\exp\left(- \dfrac{n\gamma^2p_{\text{min},i}^2}{8} \right) + \dfrac{2\gamma}{u}\exp\left( -\dfrac{np_{\text{min},i}u}{8} \right)
\]


\textit{démonstration:} Ce théorème donne une borne exponentielle sur la précision de l'algorithme. Le démonstration est longue.\\

Découpons l'intervalle \([d_i^l - \gamma, d_i^l + \gamma]\) en intervalles \((I_j)_j\) de taille \(u\). Pour tout \(j\), on pose \(N_j = \#I_j\). On note alors \(A\) l'événement ``pour tout \(j\), \(N_j \geq nup_{\text{min}, i}/2\)'' et \(B_i\) l'événement ``\(|d_i^l - d_i| \geq \gamma/2\)''.\\
\begin{align*}
    \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \right) & = \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ A \wedge B_i\right)\mathbb P\left( A \wedge B_i \right)\\
    & \quad \quad  + \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ \overline A \vee \overline B_i\right) \mathbb P \left( \overline A \vee \overline B_i \right)\\
    & \leq \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ A \wedge B_i\right) +   \mathbb P \left( \overline A \vee \overline B_i \right)\\
    & = \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ A \wedge B_i\right) +   \mathbb P \left( (\overline A \wedge B_i) \vee \overline B_i \right)\\
    & \leq \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ A \wedge B_i\right) +   \mathbb P \left( \overline A \wedge B_i\right) + \mathbb P \left( \overline B_i \right)\\
    & = \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ A \wedge B_i\right) +   \mathbb P \left( \overline A \ |\ B_i\right)\mathbb P (B_i) + \mathbb P \left( \overline B_i \right)\\
    & \leq \mathbb P\left( |M_{\text{cont}, i} - d_i^l| > 2u + \rho \ | \ A \wedge B_i\right) +   \mathbb P \left( \overline A \ |\ B_i\right) + \mathbb P \left( \overline B_i \right)\\
\end{align*}

Nous savons que si les événements \(A\) et \(B\) surviennent, pour tout \(t\) tel que \(|t - d_i| > 2u\), au moins \(nup_{\text{min}, i}/2\) éléments séparent \(d_i\) et \(t\). Pour de tels \(t\) nous avons alors \(\len_f(x,t) \geq nup_{\text{min}, i}/2\). Ainsi, pour tout \(s\) tel que \(|s - d_i| > 2u + \rho\), \(\len_f^\rho(x,s) \geq nup_{\text{min}, i}/2\). Enfin, pour tout \(t\) tel que \(|t - d_i| > 2u + \rho\),
\begin{align*}
    \pi_P\left( t\ |\ A \wedge B \right) & = \dfrac{\exp\left( -{\len_f^\rho(x,t)\varepsilon}/{2} \right)}{\int_\mathcal T \exp\left( {-\len_f^\rho(x,s)\varepsilon}/{2} \right)\dt \mu(s)}\\
    & \leq \dfrac{\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)}{\int_\mathcal T \exp\left( {-\len_f^\rho(x,s)\varepsilon}/{2} \right)\dt \mu(s)}\\
    & \leq \dfrac{\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)}{\int_{d_i-\rho}^{d_i+\rho} \exp\left( {-\len_f^\rho(x,s)\varepsilon}/{2} \right)\dt \mu(s)}\\
    & = \dfrac{\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)}{\int_{d_i-\rho}^{d_i+\rho}\dt \mu(s)}\\
    & = \dfrac{\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)}{2\rho}\\
\end{align*}

Ainsi,
\begin{align*}
    \mathbb P\left( |M_{\text{cont}} - d_i| > 2u + \rho \ | \ A \wedge B_i\right) & \leq \int_\mathcal T \dfrac{\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)}{2\rho}\un_{| t - d_i| > 2u + \rho} \dt\mu(t)\\
    & \leq \dfrac{\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)}{2\rho} \mu(\mathcal T)\\
    & = \dfrac{R}{2\rho}\exp\left( -{nup_{\text{min}, i}\varepsilon}/{4} \right)
\end{align*}

Nous allons maintenant calculer la probabilité de l'événement \(\overline B_i\). Pour cela, on pose \(\alpha = \gamma/2\), pour tout \(j \in \inte 0 {n-1} \) on pose \(C_j^i = \un_{x_i > d_i^l + \alpha}\) et \(C^i = \sum_{j = 0}^{n-1} C_j\). L'événement \(C^i\) dénote le nombre d'éléments de \(X\) plus grands que \(d_i^l + \alpha\). Par définition de \(p_{\text{min}, i}\) assure que 
\[
    \begin{array}{rcl}
        \hat p & := & \mathbb P(C_j^i = 1)\\
        & = & 1 - \displaystyle\int_{0}^{d_i^l} \pi_P(t) \dt \mu(t) - \displaystyle \int_{d_i^l}^{d_i^l+\alpha} \pi_P(t) \dt \mu(t)\\
        & \overset{\text{déf de } d_i^l}{=} & 1 - \dfrac{i}{10} - \displaystyle\int_{d_i^l}^{d_i^l+\alpha} \pi_P(t) \dt \mu(t)\\
        & \leq & \dfrac{10 - i}{10} - \displaystyle p_{\text{min}, i}\int_{d_i}^{d_i^l+\alpha} \dt \mu(t)\\
        & = & \dfrac{10-i}{10} - \alpha p_{\text{min}, i}\\
    \end{array}
\]

Or, si \(d_i > d_i^l\), \(C^i \geq in/10\). Ainsi, en utilisant une borne de {\sc Chernoff} (\(C^i\) est d'espérance \(\hat pn\) et les \((C^i_j)_j\) sont indépendantes),
\begin{align*}
    \mathbb P\left( d_i > d_i^l + \alpha \right)& \leq \mathbb P \left( C^i \geq \dfrac{in}{10}\right)\\
    % & = \mathbb P \left( \sum_{j = 0}^{n-1}C^i_j \geq \hat pn\left( 1 + \dfrac{i}{\hat p 10} -1\right)\right)\\
    & = \mathbb P \left( \sum_{j = 0}^{n-1}C^i_j \geq \hat pn\left( 1 - \left(1 - \dfrac{i}{\hat p 10}\right)\right)\right)\\
    & \leq \exp\left( -\left(1 - \dfrac{i}{\hat p 10}\right)^2\dfrac{n\hat p}{2}\right)\\
    & = \exp\left( -\left(\hat p - \dfrac{i}{10}\right)^2\dfrac{n}{2\hat p}\right)\\
    & \leq \exp\left( -\left(\alpha p_{\text{min}, i}\right)^2\dfrac{n}{2\hat p}\right)\\
    & \leq \exp\left( -\alpha^2 p_{\text{min}, i}^2\dfrac{n}{i/5 - 2\alpha p_{\text{min}, i}}\right)\\
    & \leq \exp\left( -\dfrac{1}{2}\alpha^2 p_{\text{min}, i}^2n\right)\\
\end{align*}

On montre alors de même que \(\mathbb P\left( d_i < d_i^l - \alpha \right) < \exp\left( -\dfrac{1}{2}\alpha^2 p_{\text{min}, i}^2n\right)\). Nous avons donc montré que 
\[
    \mathbb P \left( B_i \right) \geq 1 - 2\exp\left( -\dfrac{1}{8}n\gamma^2 p_{\text{min}, i}^2\right)
\]

Finalement, il ne nous reste plus qu'à minorer \(\mathbb P (A\ | \ B_i)\)! Pour cela, notons que 
\[
    \mathbb P (A\ | \ B_i) \geq (A\ | \ B_i)\mathbb P(B_i) = \mathbb P (A) - \mathbb P \left( A \wedge \overline B_i \right) \geq \mathbb P (A) - \mathbb P (\overline B_i)
\]

Pour tout \(k \leq n - 1\) on pose alors \(Z_k = \un_{x_k \in I_j}\) et on a \(N_j = \sum_{k = 0}^{n-1} Z_k\). On note que \(\mathbb P (Z_j = 1) \geq u p_{\text{min}, i}\). Utiliser une nouvelle fois une borne de {\sc Chernoff} assure enfin que 
\[
    \mathbb P \left( N_j < n u p_{\text{min}, i}/2\right) = \mathbb P \left( N_j < n u p_{\text{min}, i} \left( 1 - \dfrac{1}{2} \right)\right) < \exp\left( - \dfrac{1}{8}n u p_{\text{min}, i} \right)
\]

Enfin,
\[
  \mathbb P \left( \overline A \right)  = \mathbb P \left( \bigcup_{j = 0}^{2\gamma /u} N_j < n u p_{\text{min}, i}/2  \right) \leq \sum_{j = 0}^{2\gamma/u} \mathbb P \left( N_j < n u p_{\text{min}, i}/2 \right) \leq \dfrac{2\gamma}{u}\exp\left( - \dfrac{1}{8}n u p_{\text{min}, i} \right)
\]


On obtient alors 
\[
    \mathbb P (A\ | \ B_i) \geq 1 - \dfrac{2\gamma}{u}\exp\left( - \dfrac{1}{8}n u p_{\text{min}, i} \right) - 2\exp\left( -\dfrac{1}{8}n\gamma^2 p_{\text{min}, i}^2\right) 
\]

Ce que nous permet alors d'obtenir le résultat recherché!





















\newpage
\pagenumbering{roman}
\appendix
\section{HistogramMethod: Analyse de précision - le cas de la loi normale centrée réduite}
\label{hmncr}
\subsection{Démonstration du lemme [\ref{ecard_deciles_empirique_loi_n01}]}

\lemme{Estimation de l'écard entre les déciles empiriques et ceux de la loi normale centrée réduite.}\\
Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi normale centrée réduite et soit \(\gamma \in [0, d_i^l]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) les déciles de la loi normale centrée réduite. Pour tout \(i \in \inte 1 9\)
\[
    \mathbb P(d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]) \geq 1 - \eta
\]
Avec 
\begin{align*}
    \eta & = \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - (d_i^l)^2\right)\right) + \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -(d_i^l)^2\right)  \right)
\end{align*}

\textit{Démonstration:} Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi uniforme sur [0,1]. Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) ceux de la loi. Soit \(\gamma \in [0,d^l_i]\). On note que
\begin{align*}
    \mathbb P(d_i \in [d^l_i - \gamma/2, d^l_i + \gamma+2]) & = 1 - \mathbb P(d_i \notin [d^l_i - \gamma/2, d^l_i + \gamma/2])\\
    & = 1 - \mathbb P(d_i \leq d^l_i - \gamma/2 \vee d_i \geq d^l_i + \gamma/2)\\
\end{align*}

On pose alors \(A = \) ``il y a au moins \(in/10\) valeurs plus petites que \(d^l_i - \gamma/2\)'' et \(B = \) ``il y a au plus \(in/10\) valeurs plus petites que \(d^l_i + \gamma/2\)''. Pour tout \(j \in \inte 0 {n-1}\) on pose \(A_j = \un_{x_j \leq d^l_i + \gamma/2}\), \(B_j = \un_{x_j \leq d^l_i + \gamma/2}\), \(A_s = \sum_{j = 0}^{n-1} A_j\) et \(B_s = \sum_{j = 0}^{n-1}B_j\). On a alors, \(A = \{A_s \geq in/10\}\) et \(B = \{B_s \leq  in/10\}\). Une application d'une borne de {\sc Chernoff} assure alors que 
\[
    \begin{array}{rcl}
        \mathbb P(A) & = & \mathbb P (A_s \geq in/10)\\
        & = & \mathbb P \left(A_s \geq \dfrac{n}{\sqrt{2\pi}}\displaystyle\int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( \dfrac{-t^2}{2} \right)\dt t  \left( 1 + \dfrac{i\sqrt{2\pi}}{10\int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( {-t^2}/{2} \right)\dt t}  - 1\right)\right)\\
        & \overset{d_i ^l \geq \gamma}{\leq} & \exp\left( - \dfrac{n}{3\sqrt{2\pi}}\displaystyle\int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( \dfrac{-t^2}{2} \right)\dt t\left( \dfrac{i\sqrt{2\pi}}{10\int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( {-t^2}/{2} \right)\dt t}  - 1 \right)^2\right)\\
        & = & \exp\left( - \dfrac{n}{3} \left( \dfrac{i}{10} - \dfrac{1}{\sqrt{2\pi}}\displaystyle\int_{d^l_i - \gamma/2}^{d_i^l}  \exp\left( \dfrac{-t^2}{2} \right)\dt t \right)\left( \dfrac{i\sqrt{2\pi}}{10\int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( {-t^2}/{2} \right)\dt t}  - 1 \right)^2\right)\\
        & \leq & \exp\left( - \dfrac{n}{3} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\left( \dfrac{i\sqrt{2\pi}}{10\int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( {-t^2}/{2} \right)\dt t}  - 1 \right)^2\right)
    \end{array}
\]


Or, la valeurs des déciles de la loi normale centrée réduite étant connues \ref{val_deciles_n01},
\begin{align*}
    \dfrac{1}{\sqrt{2\pi}} \int_{-\infty}^{d^l_i - \gamma/2}   \exp\left( \dfrac{-t^2}{2} \right)\dt t & = \dfrac{1}{2}\dfrac{2}{\sqrt{\pi}}  \int_{-\infty}^{(d^l_i - \gamma/2)/\sqrt 2}   \exp\left( {-t^2} \right)\dt t\\
    & = \dfrac{1}{2} + \dfrac{1}{2}\erf\left( \dfrac{d^l_i - \gamma/2}{\sqrt 2 }\right)\\
    & = \dfrac{1}{2} + \dfrac{1}{2}\erf\left( \erf^{-1}\left( 2\times 0.1i - 1 \right) - \dfrac{\gamma}{2\sqrt 2 }\right)\\
    & = \dfrac{1}{2} + \dfrac{1}{2}\erf\left( \erf^{-1}\left( 2\times 0.1i - 1 \right)\right) - \dfrac{1}{\sqrt{\pi}}\int_{\erf^{-1}\left( 2\times 0.1i - 1 \right) - \gamma/2\sqrt 2}^{\erf^{-1}\left( 2\times 0.1i - 1 \right)} \exp\left( -t^2 \right)\dt t\\
    & = \dfrac{i}{10} - \dfrac{1}{\sqrt{\pi}}\int_{\erf^{-1}\left( 2\times 0.1i - 1 \right) - \gamma/2\sqrt 2}^{\erf^{-1}\left( 2\times 0.1i - 1 \right)} \exp\left( -t^2 \right)\dt t\\
    & \leq \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}} \exp\left( - \erf^{-1}\left(2\times 0.1i - 1 \right)^2\right) \\
\end{align*}

Enfin, comme \(25/(6\pi) \geq 5\),
\begin{align*}
    \mathbb P(A) & \leq \exp\left( - \dfrac{n}{3} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\left( \dfrac{i}{i - {5\gamma}/{\sqrt{2\pi}} \exp\left( - \erf^{-1}\left(2\times 0.1i - 1 \right)^2\right)}  - 1 \right)^2\right)\\
    & \leq \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - 2\erf^{-1}\left(2\times 0.1i - 1 \right)^2\right)\right)\\
    & = \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - (d_i^l)^2\right)\right)
\end{align*}

Finalement,
\begin{align*}
    \mathbb P (B) & = \mathbb P \left( B_s \leq in/10 \right)\\
    &= \mathbb P\left( B_s \leq \dfrac{n}{\sqrt{2\pi}}\left( \int_{-\infty}^{d_i^l + \gamma/2} \exp\left( -\dfrac{t^2}{2}\dt t \right) \right)\left( 1 - \left( 1 - \dfrac{i\sqrt{2\pi}}{10\int_{-\infty}^{d_i^l + \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t}  \right)\right)  \right)\\
    & \leq \exp \left( - \dfrac{n}{2\sqrt{2\pi}}\left( \int_{-\infty}^{d_i^l + \gamma/2} \exp\left( -\dfrac{t^2}{2}\dt t \right) \right)\left( 1 - \dfrac{i\sqrt{2\pi}}{10\int_{-\infty}^{d_i^l + \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t}  \right)^2  \right)\\
    & \leq \exp \left( - \dfrac{in}{20}\left( 1 - \dfrac{i}{i + 5\gamma/\sqrt{2\pi} \exp\left( -(\erf^{-1}\left(2\times 0.1i - 1 \right) + \gamma/2) ^2\right)}  \right)^2  \right)\\
    &  = \exp \left( - \dfrac{25 \gamma^2in}{40\pi}\left(\dfrac{\exp\left( -(\erf^{-1}\left(2\times 0.1i - 1 \right) + \gamma/2)^2\right)}{i + 5\gamma/\sqrt{2\pi} \exp\left( -(d_i^l + \gamma/2)^2\right)}  \right)^2  \right)\\
    &  \leq \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -2(\erf^{-1}\left(2\times 0.1i - 1 \right) + \gamma/2)^2\right)  \right)\\
    &  \leq \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -(d_i^l)^2\right)  \right)\\
\end{align*}


\subsection{Démonstration du lemme [\ref{ecard_deciles_empirique_loi_n02}]}
\lemme{}

Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la normale centrée réduite. Soit \(\gamma \in [0,d^l_i]\), \(i \in \inte 1 9 \) et \(k \in \N\). Il y a au moins \(\alpha\) valeurs de \(X\) dans chacun des intervalles \([d^l_i - \gamma, d^l_i-\gamma/2]\) et \([d^l_i + \gamma/2, d^l_i+\gamma]\) avec une probabilité au moins \(1 - \beta\) avec 
\begin{align*}
    \beta & = 2\exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)
\end{align*}

\textit{Démonstration:} Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi normale centrée réduite. Soit \(\gamma \in [0,d^l_i]\), \(i \in \inte 1 9 \) et \(\alpha \in \N\). On pose \(A = \) ``il y a au moins \(\alpha\) valeurs dans l'intervalle \([d^l_i - \gamma, d_i^l - \gamma/2]\)'' et \(B = \) ``il y a au moins \(\alpha\) valeurs dans l'intervalle \([d^l_i + \gamma/2, d_i^l + \gamma]\)''. Pour tout \(j \in \inte 0 {n-1}\) on pose \(A_j = \un_{x_j \in [d^l_i - \gamma, d_i^l - \gamma/2]}\), \(B_j = \un_{x_j \in [d^l_i + \gamma/2, d_i^l + \gamma]}\), \(A_s = \sum_{j = 0}^{n-1} A_j\) et \(B_s = \sum_{j = 0}^{n-1}B_j\). On a alors, \(A = \{A_s \geq \alpha\}\) et \(B = \{B_s \geq  \alpha\}\).
\begin{align*}
    \mathbb P \left( A\ \wedge\ B \right) &= \mathbb P\left( A_s \geq \alpha \ \wedge \ B_s \geq \alpha \right)\\
    & \geq \mathbb P\left( A_s \geq \alpha \right) + \mathbb P \left(B_s \geq \alpha \right) - 1\\
    & = 1 - \mathbb P\left( A_s < \alpha \right) - \mathbb P \left(B_s < \alpha \right)\\
\end{align*}

Une application d'une borne de {\sc Chernoff} assure alors que 
\begin{align*}
    \mathbb P\left( A_s < \alpha \right) & = \mathbb P\left( A_s < \dfrac{n}{\sqrt{2\pi}}\int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -\dfrac{t^2}{2} \right)\dt t \left( 1 - \left(1 - \dfrac{\alpha\sqrt{2\pi}}{n \int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t} \right) \right)\right) \\
    & \leq \exp\left( -\dfrac{n}{2\sqrt{2\pi}}\int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -\dfrac{t^2}{2} \right)\dt t  \left(1 - \dfrac{\alpha\sqrt{2\pi}}{n \int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t} \right)^2\right)\\
    & \leq \exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}} \exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  \left(\dfrac{n \int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t - \alpha\sqrt{2\pi}}{n \int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t} \right)^2\right)\\
    & \leq \exp\left( -\dfrac{1}{n\gamma\sqrt{2\pi}} \exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  \left(n \int_{d^l_i - \gamma}^{d^l_i - \gamma/2} \exp\left( -{t^2}/{2} \right)\dt t - \alpha\sqrt{2\pi} \right)^2\right)\\
    & \leq \exp\left( -\dfrac{n}{\gamma\sqrt{2\pi}} \exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  \left( \dfrac{\gamma}{2}\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{\alpha\sqrt{2\pi}}{n} \right)^2\right)\\
    & \leq \exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)\\
\end{align*}

Nous pourrions alors montrer, exactement de la même manière que 
\begin{align*}
    \mathbb P\left( B_s < \alpha \right) & \leq \exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)\\
\end{align*}

Finalement,
\[
    \mathbb P \left( A\ \wedge\ B \right) \geq 1 - 2\exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)
\]

\subsection{Démonstration du théorème [\ref{ecard_deciles_empirique_loi_n03}]}

\theoreme{\((\alpha, \beta)\)-précision de \mintinline{cpp}{HistogramMethod} dans le cas de la loi normale centrée réduite}

Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi normale centrée réduite. Soit \(\gamma \in [0,d_i^l]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) les déciles de la loi normale centrée réduite. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}.

\[
    \mathbb P\left( A_i \in [d_i^l-\gamma, d_i^l + \gamma] \right) \geq 1 - \beta - \eta -\mu    
\]
Avec 
\[
    \left\{ 
        \begin{array}{rl}
            \alpha & = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon} \\
            \mu & = 2\exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)\\
            \eta & = \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - (d_i^l)^2\right)\right) + \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -(d_i^l)^2\right)  \right)\\
        \end{array}
    \right.     
\] 

\textit{Démonstration:} Soit \(X\) un ensemble de \(n\) variables aléatoires \((X_i)_i\) indépendantes et suivant toutes la loi normale centrée réduite. Soit \(\gamma \in [0,d_i^l]\), \(i \in \inte 1 9 \), \(k \in \N\) et \(\beta \in [0,1]\). Notons \((d_i)_i\) les déciles empiriques de \(X\) et \((d_i^l)_i\) les déciles de la loi normale centrée réduite. Posons \(A\) la variable aléatoire \mintinline{cpp}{HistogramMethod(X, epsilon, k, a, b)}.\\

On pose 
\[
    \alpha = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon}    
\]

Notons alors \(E_\alpha\) l'événement ``Il y a au moins \(\alpha\) valeurs de \(X\) dans chacun des intervalles \([d_i^l - \gamma, d_i^l-\gamma/2]\) et \([d_i^l + \gamma/2, d_i^l+\gamma]\)'' Et \(E_{A_i}\) l'événement ``moins de \(\alpha\) valeurs de \(X\) séparent \(d_i\) et \(A_i\)''. Nous avons alors 
\begin{align*}
    \mathbb P\left( A_i \in [d_i^l-\gamma, d_i^l + \gamma] \right) & \geq \mathbb P \left( E_{A_i} \wedge E_\alpha \wedge d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]  \right)\\
    & \geq \mathbb P \left( E_{A_i}\right) + \mathbb P \left( E_\alpha\right) + \mathbb P \left( d_i \in [d_i^l - \gamma/2, d_i^l + \gamma/2]  \right) - 2\\
\end{align*}

Les lemmes précédent assurent alors que 
\begin{align*}
    \mathbb P\left( A_i \in [0.1i-\gamma, 0.1i + \gamma] \right) & \geq (1 - \beta) + (1 - \mu) + (1 - \eta) - 2\\
    & \geq 1 - \beta - \mu - \eta
\end{align*}

Avec 
\[
    \left\{ 
        \begin{array}{rl}
            \alpha & = \dfrac{8\left( \log k + \log(2/\beta) \right)}{\varepsilon} \\
            \mu & = 2\exp\left( -\dfrac{n\gamma}{4\sqrt{2\pi}}  \left(\exp\left( -\dfrac{(|d_i^l| + \gamma)^2}{2} \right)  - \dfrac{2\alpha\sqrt{2\pi}}{n\gamma} \right)^3\right)\\
            \eta & = \exp\left( - \dfrac{n\gamma^2}{i^2} \left( \dfrac{i}{10} - \dfrac{\gamma}{2\sqrt{2\pi}}\right)\exp\left( - (d_i^l)^2\right)\right) + \exp \left( - \dfrac{5 \gamma^2in}{16\pi \left( i + 5\gamma/\sqrt{2\pi} \right)^2}\exp\left( -(d_i^l)^2\right)  \right)\\
        \end{array}
    \right.    
\]
\newpage
\printbibliography
% \vspace{30px}
% \vspace{15px}


\end{document} 